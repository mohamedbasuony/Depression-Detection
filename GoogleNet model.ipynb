{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "600012cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for googlenet\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.multiprocessing as mp\n",
    "from torch.utils.data.sampler import Sampler\n",
    "from torchvision import datasets, transforms\n",
    "import json\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "from googlenet_pytorch import GoogLeNet \n",
    "\n",
    "\n",
    "from googlenet_pytorch import GoogLeNet \n",
    "model = GoogLeNet.from_pretrained('googlenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4ee28a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(rank, args, model, device, dataset, dataloader_kwargs):\n",
    "    torch.manual_seed(args.seed + rank)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset, **dataloader_kwargs)\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        train_epoch(epoch, args, model, device, train_loader, optimizer)\n",
    "\n",
    "\n",
    "\n",
    "def train_epoch(epoch, args, model, device, data_loader, optimizer):\n",
    "    model.train()\n",
    "    pid = os.getpid()\n",
    "    for batch_idx, (data, target) in enumerate(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.to(device))\n",
    "        loss = F.nll_loss(output, target.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('{}\\tTrain Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                pid, epoch, batch_idx * len(data), len(data_loader.dataset),\n",
    "                100. * batch_idx / len(data_loader), loss.item()))\n",
    "            if args.dry_run:\n",
    "                break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b07b243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args, model, device, dataset, dataloader_kwargs):\n",
    "    torch.manual_seed(args.seed)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(dataset, **dataloader_kwargs)\n",
    "\n",
    "    test_epoch(model, device, test_loader)\n",
    "    \n",
    "\n",
    "def test_epoch(model, device, data_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            output = model(data.to(device))\n",
    "            test_loss += F.nll_loss(output, target.to(device), reduction='sum').item() # sum up batch loss\n",
    "            pred = output.max(1)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.to(device)).sum().item()\n",
    "\n",
    "    test_loss /= len(data_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(data_loader.dataset),\n",
    "        100. * correct / len(data_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c64ec75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open image\n",
    "input_image = Image.open(\"/Users/mohamedbasuony/Desktop/Research/save/236_1_Northwind_video/790.png\")\n",
    "\n",
    "# Preprocess image\n",
    "preprocess = transforms.Compose([\n",
    "  transforms.Resize(256),\n",
    "  transforms.CenterCrop(224),\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0)  # create a mini-batch as expected by the model\n",
    "\n",
    "# Load class names\n",
    "labels_map = json.load(open(\"/Users/mohamedbasuony/Desktop/Research/AV2014_Training_data_NYU/Training_DepressionLabels/236_1_Depression.csv\"))\n",
    "labels_map = [labels_map for i in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0a992ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--batch-size N] [--test-batch-size N]\n",
      "                             [--epochs N] [--lr LR] [--momentum M] [--seed S]\n",
      "                             [--log-interval N] [--num-processes N] [--cuda]\n",
      "                             [--mps] [--dry-run]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /Users/mohamedbasuony/Library/Jupyter/runtime/kernel-c37ca95f-8923-40ee-8ce4-3bd569a1e6ab.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
    "                    help='input batch size for training (default: 64)')\n",
    "parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n",
    "                    help='input batch size for testing (default: 1000)')\n",
    "parser.add_argument('--epochs', type=int, default=10, metavar='N',\n",
    "                    help='number of epochs to train (default: 10)')\n",
    "parser.add_argument('--lr', type=float, default=0.01, metavar='LR',\n",
    "                    help='learning rate (default: 0.01)')\n",
    "parser.add_argument('--momentum', type=float, default=0.5, metavar='M',\n",
    "                    help='SGD momentum (default: 0.5)')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                    help='random seed (default: 1)')\n",
    "parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "                    help='how many batches to wait before logging training status')\n",
    "parser.add_argument('--num-processes', type=int, default=2, metavar='N',\n",
    "                    help='how many training processes to use (default: 2)')\n",
    "parser.add_argument('--cuda', action='store_true', default=False,\n",
    "                    help='enables CUDA training')\n",
    "parser.add_argument('--mps', action='store_true', default=False,\n",
    "                        help='enables macOS GPU training')\n",
    "parser.add_argument('--dry-run', action='store_true', default=False,\n",
    "                    help='quickly check a single pass')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = parser.parse_args()\n",
    "    print(\"here\")\n",
    "\n",
    "\n",
    "    use_cuda = args.cuda and torch.cuda.is_available()\n",
    "    use_mps = args.mps and torch.backends.mps.is_available()\n",
    "    if use_cuda:\n",
    "        device = torch.device(\"cuda\")\n",
    "    elif use_mps:\n",
    "        device = torch.device(\"mps\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "    dataset1 = datasets.MNIST('/Users/mohamedbasuony/Desktop/Research/videos source/vids frames/332_2_Northwind_video', train=True, download=True,\n",
    "                       transform=transform)\n",
    "    dataset2 = datasets.MNIST('/Users/mohamedbasuony/Desktop/Research/videos source/vids frames/320_1_Northwind_video', train=False,\n",
    "                       transform=transform)\n",
    "    kwargs = {'batch_size': args.batch_size,\n",
    "              'shuffle': True}\n",
    "    if use_cuda:\n",
    "        kwargs.update({'num_workers': 1,\n",
    "                       'pin_memory': True,\n",
    "                      })\n",
    "\n",
    "    torch.manual_seed(args.seed)\n",
    "    mp.set_start_method('spawn', force=True)\n",
    "\n",
    "    model = Net().to(device)\n",
    "    model.share_memory() # gradients are allocated lazily, so they are not shared here\n",
    "\n",
    "    processes = []\n",
    "    for rank in range(args.num_processes):\n",
    "        p = mp.Process(target=train, args=(rank, args, model, device,\n",
    "                                           dataset1, kwargs))\n",
    "        # We first train the model across `num_processes` processes\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "\n",
    "    # Once training is complete, we can test the model\n",
    "    test(args, model, device, dataset2, kwargs)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b102d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
